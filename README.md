# Toxicometer
Try it out at https://abhinandanroul.github.io/Toxicometer/
A real-time toxic comment detector.<br><br>
Have you ever felt that you accidentaly posted explicit comments which you don't intend? I know, sometimes we become so frustrated with our lives and the myriad things that go around us, that we release all our anger on online posts. We don't do that intentionally though, but we can't always stop it from happening. Our minds are not always calm and stable. <br><br>
Here, comes Toxicometer. A tool which classifies the comments and warns the user (Yes, I'm talking about YOU) that the comment is toxic and you need to look into your words, AGAIN. <br>It also tells you whenever you post clean comments, so that you know that your comments aren't violating community guidelines. <br> To be honest, it can also save you from getting banned. <br> Made possible by Jigsaw's Conversation-AI.

![Clean](https://github.com/AbhinandanRoul/Toxicometer/blob/master/Snips/Clean.png) ![Toxic](https://github.com/AbhinandanRoul/Toxicometer/blob/master/Snips/Toxic.png)

